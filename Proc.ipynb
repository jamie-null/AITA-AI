{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo: find a way to handle legacy posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index setting required due to index setting not being in place\n",
    "import pandas as pd\n",
    "with pd.HDFStore(\"store.h5\") as store:\n",
    "    pdf = store['pdf'].set_index('id').sort_index()\n",
    "    cdf = store['cdf'].set_index(['parent_id', 'position']).sort_index()\n",
    "    rdf = store['rdf'].set_index('name').sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcting two bugs in the original scraper script, don't wish to run it for another dozen hours again\n",
    "from praw.models import Redditor\n",
    "\n",
    "#first issue is that some praw objects were stored instread of author strings, this replaces them without fetching them from reddit\n",
    "s = pdf['author']\n",
    "pdf['author'] = s.apply(lambda x: x.name if isinstance(x, Redditor) else x)\n",
    "\n",
    "#second, redditor entries found in the comments were duplicated due to a missing line that would have added them to the set\n",
    "#there isn't an easy way to fix this without starting over\n",
    "#I'm just dropping all author entires without a created data (used for throwawy detection)\n",
    "rdf = rdf.dropna(subset=['created_utc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>edited</th>\n",
       "      <th>gilded</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parent_id</th>\n",
       "      <th>position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t3_b8z9ed</th>\n",
       "      <th>86</th>\n",
       "      <td>None</td>\n",
       "      <td>NYA- people can and do break up after 4 years ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-03 17:33:56</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_b59mn5</th>\n",
       "      <th>27</th>\n",
       "      <td>notyourcoloringbook</td>\n",
       "      <td>NTA</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-26 01:41:48</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_bf81s0</th>\n",
       "      <th>13</th>\n",
       "      <td>badiatorsweg</td>\n",
       "      <td>Yeah you’re right prescription drugs aren’t th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-20 03:42:09</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_bzg67o</th>\n",
       "      <th>5</th>\n",
       "      <td>FredFredFredFredFres</td>\n",
       "      <td>INFO. Did you ever confront him about not visi...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-11 18:25:28</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_b04x43</th>\n",
       "      <th>8</th>\n",
       "      <td>Heighwayqueen</td>\n",
       "      <td>Ywbta It sounds like something has changed for...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-12 07:36:32</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_b2i8xj</th>\n",
       "      <th>25</th>\n",
       "      <td>DoctorDashDash</td>\n",
       "      <td>Why do people post stories in AITA when they'r...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-18 15:32:04</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_bo5wag</th>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>NAH - Theres nothing wrong with being proud of...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-13 16:51:48</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_b9e9b8</th>\n",
       "      <th>116</th>\n",
       "      <td>DikkAntlers</td>\n",
       "      <td>ESH but very good idea</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-04-04 21:49:08</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_bnlhzz</th>\n",
       "      <th>4</th>\n",
       "      <td>alaskahro</td>\n",
       "      <td>NTA. It is ultimately your living space and yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-12 05:20:08</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3_bta48a</th>\n",
       "      <th>264</th>\n",
       "      <td>savvysails</td>\n",
       "      <td>Ok so I don’t get it, the parent is okay with ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-27 00:10:50</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  author  \\\n",
       "parent_id position                         \n",
       "t3_b8z9ed 86                        None   \n",
       "t3_b59mn5 27         notyourcoloringbook   \n",
       "t3_bf81s0 13                badiatorsweg   \n",
       "t3_bzg67o 5         FredFredFredFredFres   \n",
       "t3_b04x43 8                Heighwayqueen   \n",
       "t3_b2i8xj 25              DoctorDashDash   \n",
       "t3_bo5wag 5                         None   \n",
       "t3_b9e9b8 116                DikkAntlers   \n",
       "t3_bnlhzz 4                    alaskahro   \n",
       "t3_bta48a 264                 savvysails   \n",
       "\n",
       "                                                                 body  \\\n",
       "parent_id position                                                      \n",
       "t3_b8z9ed 86        NYA- people can and do break up after 4 years ...   \n",
       "t3_b59mn5 27                                                      NTA   \n",
       "t3_bf81s0 13        Yeah you’re right prescription drugs aren’t th...   \n",
       "t3_bzg67o 5         INFO. Did you ever confront him about not visi...   \n",
       "t3_b04x43 8         Ywbta It sounds like something has changed for...   \n",
       "t3_b2i8xj 25        Why do people post stories in AITA when they'r...   \n",
       "t3_bo5wag 5         NAH - Theres nothing wrong with being proud of...   \n",
       "t3_b9e9b8 116                                  ESH but very good idea   \n",
       "t3_bnlhzz 4         NTA. It is ultimately your living space and yo...   \n",
       "t3_bta48a 264       Ok so I don’t get it, the parent is okay with ...   \n",
       "\n",
       "                    controversiality         created_utc distinguished edited  \\\n",
       "parent_id position                                                              \n",
       "t3_b8z9ed 86                       0 2019-04-03 17:33:56          None    NaT   \n",
       "t3_b59mn5 27                       0 2019-03-26 01:41:48          None    NaT   \n",
       "t3_bf81s0 13                       0 2019-04-20 03:42:09          None    NaT   \n",
       "t3_bzg67o 5                        0 2019-06-11 18:25:28          None    NaT   \n",
       "t3_b04x43 8                        0 2019-03-12 07:36:32          None    NaT   \n",
       "t3_b2i8xj 25                       0 2019-03-18 15:32:04          None    NaT   \n",
       "t3_bo5wag 5                        0 2019-05-13 16:51:48          None    NaT   \n",
       "t3_b9e9b8 116                      0 2019-04-04 21:49:08          None    NaT   \n",
       "t3_bnlhzz 4                        0 2019-05-12 05:20:08          None    NaT   \n",
       "t3_bta48a 264                      0 2019-05-27 00:10:50          None    NaT   \n",
       "\n",
       "                    gilded  score  \n",
       "parent_id position                 \n",
       "t3_b8z9ed 86             0     15  \n",
       "t3_b59mn5 27             0      2  \n",
       "t3_bf81s0 13             0     -7  \n",
       "t3_bzg67o 5              0      2  \n",
       "t3_b04x43 8              0      1  \n",
       "t3_b2i8xj 25             0     11  \n",
       "t3_bo5wag 5              0     18  \n",
       "t3_b9e9b8 116            0      1  \n",
       "t3_bnlhzz 4              0      2  \n",
       "t3_bta48a 264            0      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdf['link_flair_text'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a list of a_inf (needs more info/uncertain), a_op (OP is the asshole), a_to (the other person is the asshole)\n",
    "def flair_to_label(row):\n",
    "    flair = row['link_flair_text']\n",
    "    if flair in ['Not enough info', 'not enough info','too close to call','Too close to call']:\n",
    "        row['label'] = -1\n",
    "        #row['a_inf'] = True\n",
    "    elif flair in ['No A-holes here','no a--holes here','no assholes here']:\n",
    "        row['label'] = 0\n",
    "        #row['a_inf'], row['a_op'], row['a_to'] = [False, False, False]\n",
    "    elif flair in ['Not the A-hole','not the a-hole','not the asshole']:\n",
    "        row['label'] = 1\n",
    "        #row['a_inf'], row['a_op'], row['a_to'] = [False, False, True]\n",
    "    elif flair in ['Asshole','asshole']:\n",
    "        row['label'] = 2\n",
    "        #row['a_inf'], row['a_op'], row['a_to'] = [False, True, False]\n",
    "    elif flair in ['Everyone Sucks','everyone sucks']:\n",
    "        row['label'] = 3\n",
    "        #row['a_inf'], row['a_op'], row['a_to'] = [False, True, True]\n",
    "    return row\n",
    "\n",
    "print('Total before flair processing:' + str(len(pdf)))\n",
    "df = pdf.apply(flair_to_label,axis=1).dropna(subset=['label'])\n",
    "print('Total after: ' + str(len(df)))\n",
    "print(df['label'].value_counts())\n",
    "#print(df['a_op'].value_counts())\n",
    "#print(df['a_to'].value_counts())\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/761824/python-how-to-convert-markdown-formatted-text-to-text\n",
    "from markdown import Markdown\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "def unmark_element(element, stream=None):\n",
    "    if stream is None:\n",
    "        stream = StringIO()\n",
    "    if element.text:\n",
    "        stream.write(element.text)\n",
    "    for sub in element:\n",
    "        unmark_element(sub, stream)\n",
    "    if element.tail:\n",
    "        stream.write(element.tail)\n",
    "    return stream.getvalue()\n",
    "\n",
    "\n",
    "# patching Markdown\n",
    "Markdown.output_formats[\"plain\"] = unmark_element\n",
    "__md = Markdown(output_format=\"plain\")\n",
    "__md.stripTopLevelTags = False\n",
    "\n",
    "\n",
    "def unmark(text):\n",
    "    return __md.convert(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\" It is a record of the post as originally written, in case the post is deleted or edited.*  \\n\\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/AmItheAsshole) if you have any questions or concerns.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import re\n",
    "\n",
    "#aita = re.compile(r\"\\baita\\b\",re.IGNORECASE)\n",
    "#wibta = re.compile(r\"\\bwibta\\b\",re.IGNORECASE)\n",
    "#deferring these for export notebook\n",
    "\n",
    "def genFeats(row):\n",
    "    #detect edit, attempt to undo if possible due to correlation between edits & YTA\n",
    "    #we wish to avoid introducing spurrious correlations that BERT may pick up on\n",
    "    #see: https://arxiv.org/abs/1907.07355\n",
    "    row['isEdited'] = 0\n",
    "    if row['edited'] == row['edited']:\n",
    "        row['isEdited'] = 1\n",
    "        for itx, comment in cdf.loc[\"t3_\"+row.name].query('distinguished == distinguished').iterrows():\n",
    "            if comment.body[-316:-280] == \"\\n\\n*This is a copy of the above post.\":\n",
    "                row['isEdited'] = 0\n",
    "                row['selftext'] = comment.body[:-316]\n",
    "            if comment.body[:58] == \"^^^^AUTOMOD  ***The following is a copy of the above post.\":\n",
    "                row['isEdited'] = 0\n",
    "                row['selftext'] = comment.body[175:-188]\n",
    "            if comment.body[:49] == \"^^^^AUTOMOD  ***This is a copy of the above post.\":\n",
    "                row['isEdited'] = 0\n",
    "                row['selftext'] = comment.body[143:-188]\n",
    "                \n",
    "    row['selftext'] = unmark(re.sub(r\"&#x200B;\\n?\",\"\",row['selftext']))\n",
    "    #row['title'] = row['title'].replace(\"AITA\",\"Am I the asshole\").replace(\"WIBTA\",\"Would I be the asshole\")\n",
    "    #.encode('utf-8') #\n",
    "            \n",
    "#    if row['author'] is not None:\n",
    "#        row['isDeleted'] = False\n",
    "#        try:\n",
    "#            author = rdf.loc[row['author']]\n",
    "#            if author is not None:\n",
    "#                row['isThrowaway'] = (row['created_utc'] - author['created_utc'] < timedelta(days=3))\n",
    "#            else:\n",
    "#                row['isDeleted'] = True\n",
    "#        except KeyError:\n",
    "#            row['isThrowaway'] = None\n",
    "#    else:\n",
    "#        row['isDeleted'] = True\n",
    "#    return row\n",
    "\n",
    "#I don't think the throwaway check is really possible without going back to the scraper. Should have done it there.\n",
    "\n",
    "    row['sum'] = 0\n",
    "    nta, nah, esh, yta, info = [False] * 5\n",
    "    \n",
    "    def procComment(comment):\n",
    "        nonlocal nta, nah, esh, yta, info, row\n",
    "        row['sum'] += comment.score\n",
    "        \n",
    "        #INFO, NAH, NTA, YTA, ESH\n",
    "        mask = [re.search(r\"\\binfo\\b\",comment.body,re.IGNORECASE) is not None,\n",
    "               re.search(r\"\\bNAH\\b\",comment.body) is not None,\n",
    "               (re.search(r\"\\bNTA\\b\",comment.body) or re.search(r\"\\bWBNTA\\b\",comment.body) \\\n",
    "               or re.search(r\"\\bYWBNTA\\b\",comment.body) or re.search(r\"\\bWNTA\\b\",comment.body)) is not None,\n",
    "               (re.search(r\"\\bYTA\\b\",comment.body) or re.search(r\"\\bYWBTA\\b\",comment.body)) is not None,\n",
    "               re.search(r\"\\bESH\\b\",comment.body) is not None\n",
    "               ]\n",
    "#        or \"not the asshole\" in comment.body.lower()\\\n",
    "#        or \"not an asshole\" in comment.body.lower():\n",
    "#        or \"you both are assholes\" in comment.body.lower()\n",
    "#        or \"you are the asshole\" in comment.body.lower()\\\n",
    "#        or \"you're being an asshole\" in comment.body.lower() \\\n",
    "#        or \"you'd be an asshole\" in comment.body.lower() \\\n",
    "#        or \"you would be an asshole\" in comment.body.lower() \\\n",
    "#        or \"you're the asshole\" in comment.body.lower():\n",
    "        #info is commonly in lower case, but for some reason the 3 letter acronyms do not tend to be lowered\n",
    "        if mask[0]:\n",
    "            if 't_info' in row:\n",
    "                row['t_info'] = max(row['t_info'], comment.score)\n",
    "            else:\n",
    "                row['t_info'] = comment.score\n",
    "                row['m_info'] = comment.score\n",
    "        \n",
    "        fields = ['nah','nta','yta','esh']\n",
    "        \n",
    "        for i, name in enumerate(fields, start=1):\n",
    "            if mask[i]:\n",
    "                if 't_' + name in row:\n",
    "                    row['t_'+ name] += comment.score\n",
    "                else:\n",
    "                    row['t_'+ name] = comment.score\n",
    "                    \n",
    "                #if this is the only match, then maxout\n",
    "                if sum(mask) == 1:\n",
    "                    if 'm_' + name in row:\n",
    "                        row['m_'+ name] = max(comment.score,row['m_'+ name])\n",
    "                    else:\n",
    "                        row['m_'+ name] = comment.score\n",
    "                        \n",
    "    cdf.loc[\"t3_\"+row.name].query('score > 0 and distinguished != distinguished and body != \\\"[deleted]\\\"').apply(procComment,axis=1)\n",
    "    \n",
    "    #we can drop rows with no values in an numexpr query\n",
    "    for c in ['t_info','t_yta','t_nta','t_esh','t_nah','m_info','m_yta','m_nta','m_esh','m_nah']:\n",
    "        if not c in row:\n",
    "            row[c] = 0\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(10000).apply(genFeats,axis=1).query('isEdited == 1')\n",
    "#ddf['isThrowaway'].value_counts()\n",
    "#from  pytorch_transformers.tokenization_bert import BertTokenizer\n",
    "#from pathlib import Path\n",
    "#tokenizer = BertTokenizer.from_pretrained(Path('../BERT/uncased_L-12_H-768_A-12/'), do_lower_case=True)\n",
    "#with open('test.txt','w',encoding='utf-8') as f:\n",
    "#    for i, row in ddf.iterrows():\n",
    "#        print(tokenizer.tokenize(row['selftext']))\n",
    "#        f.write(row['title'] )\n",
    "#        f.write('\\n')\n",
    "#        f.write(row['selftext'])\n",
    "#        f.write('\\n--------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = df.apply(genFeats,axis=1).drop(columns=['link_flair_css_class','link_flair_text','author'])\n",
    "for l in ['locked','over_18','spoiler']:\n",
    "    ddf[l] = ddf[l].apply(lambda x: 1 if x else 0)\n",
    "with pd.HDFStore(\"store.h5\") as store:\n",
    "    store['ddf'] = ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
